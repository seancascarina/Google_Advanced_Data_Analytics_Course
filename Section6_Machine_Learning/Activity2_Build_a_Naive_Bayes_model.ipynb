{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yugMU9MjJtBl"
   },
   "source": [
    "# Activity: Build a Naive Bayes model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzWqJunmJotv"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this activity, you will build your own Naive Bayes model. Naive Bayes models can be valuable to use any time you are doing work with predictions because they give you a way to account for new information. In today's world, where data is constantly evolving, modeling with Naive Bayes can help you adapt quickly and make more accurate predictions about what could occur.\n",
    "\n",
    "For this activity, you work for a firm that provides insights for management and coaches in the National Basketball Association (NBA), a professional basketball league in North America. The league is interested in retaining players who can last in the high-pressure environment of professional basketball and help the team be successful over time. In the previous activity, you analyzed a subset of data that contained information about the NBA players and their performance records. You conducted feature engineering to determine which features would most effectively predict a player's career duration. You will now use those insights to build a model that predicts whether a player will have an NBA career lasting five years or more. \n",
    "\n",
    "The data for this activity consists of performance statistics from each player's rookie year. There are 1,341 observations, and each observation in the data represents a different player in the NBA. Your target variable is a Boolean value that indicates whether a given player will last in the league for five years. Since you previously performed feature engineering on this data, it is now ready for modeling.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTVinL1hJqoy"
   },
   "source": [
    "## Step 1: Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDIRpqkZJ4S8"
   },
   "source": [
    "### Import packages\n",
    "\n",
    "Begin with your import statements. Of particular note here are `pandas` and from `sklearn`, `naive_bayes`, `model_selection`, and `metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1nDjAJPa4lVZ"
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries and modules.\n",
    "import pandas as pd\n",
    "from sklearn import naive_bayes, model_selection, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKylHziGzY3X"
   },
   "source": [
    "### Load the dataset\n",
    "\n",
    "Recall that in the lab about feature engineering, you outputted features for the NBA player dataset along with the target variable ``target_5yrs``. Data was imported as a DataFrame called `extracted_data`. As shown in this cell, the dataset has been automatically loaded in for you. You do not need to download the .csv file, or provide more code, in order to access the dataset and proceed with this lab. Please continue with this activity by completing the following instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4ebqpNcm4BDH"
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO IMPORT YOUR DATA.\n",
    "# Load extracted_nba_players_data.csv into a DataFrame called extracted_data.\n",
    "\n",
    "df = pd.read_csv('my_extracted_nba_players_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXvtnFn5oBIG"
   },
   "source": [
    "### Display the data\n",
    "\n",
    "Review the first 10 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JWu8u19C2sn1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1340 entries, 0 to 1339\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   1340 non-null   int64  \n",
      " 1   gp           1340 non-null   int64  \n",
      " 2   min          1340 non-null   float64\n",
      " 3   fga          1340 non-null   float64\n",
      " 4   fg           1340 non-null   float64\n",
      " 5   3pa          1340 non-null   float64\n",
      " 6   3p           1340 non-null   float64\n",
      " 7   fta          1340 non-null   float64\n",
      " 8   ft           1340 non-null   float64\n",
      " 9   oreb         1340 non-null   float64\n",
      " 10  dreb         1340 non-null   float64\n",
      " 11  target_5yrs  1340 non-null   int64  \n",
      " 12  pts_per_min  1340 non-null   float64\n",
      " 13  ast_per_min  1340 non-null   float64\n",
      " 14  reb_per_min  1340 non-null   float64\n",
      " 15  blk_per_min  1340 non-null   float64\n",
      " 16  stl_per_min  1340 non-null   float64\n",
      " 17  tov_per_min  1340 non-null   float64\n",
      "dtypes: float64(15), int64(3)\n",
      "memory usage: 188.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Display the first 10 rows of data.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "df.head(10)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4zz8claq0Swi"
   },
   "source": [
    "## Step 2: Model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kgPx_MP0cuc"
   },
   "source": [
    "### Isolate your target and predictor variables\n",
    "Separately define the target variable (`target_5yrs`) and the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xO46EzS8oBIG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1340, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the y (target) variable.\n",
    "### YOUR CODE HERE ###\n",
    "df_y = df['target_5yrs']\n",
    "\n",
    "# Define the X (predictor) variables.\n",
    "### YOUR CODE HERE ###\n",
    "df_x = df.drop(['target_5yrs', 'Unnamed: 0', 'oreb', 'dreb'], axis=1)\n",
    "df_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzQNmlZ75e_Y"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about splitting your data into X and y](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/VxbUT/construct-a-naive-bayes-model-with-python).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWXkObsg5gzd"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "In `pandas`, subset your DataFrame by using square brackets `[]` to specify which column(s) to select.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU9z6ufC5n58"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Quickly subset a DataFrame to exclude a particular column by using the `drop()` function and specifying the column to drop.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xj8-Pb0N-rjW"
   },
   "source": [
    "### Display the first 10 rows of your target data\n",
    "\n",
    "Display the first 10 rows of your target and predictor variables. This will help you get a sense of how the data is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pivKfaxQ5uHZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "5    0\n",
       "6    1\n",
       "7    1\n",
       "8    0\n",
       "9    0\n",
       "Name: target_5yrs, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows of your target data.\n",
    "### YOUR CODE HERE ###\n",
    "df_y.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDls2RifZhu2"
   },
   "source": [
    "**Question:** What do you observe about the your target variable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc4IshYKzENq"
   },
   "source": [
    "The target variable consists of integers representing binary categories (0=did not stay 5years, 1=stayed at least 5 years)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2kDZK5qe-4B0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gp</th>\n",
       "      <th>min</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg</th>\n",
       "      <th>3pa</th>\n",
       "      <th>3p</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft</th>\n",
       "      <th>pts_per_min</th>\n",
       "      <th>ast_per_min</th>\n",
       "      <th>reb_per_min</th>\n",
       "      <th>blk_per_min</th>\n",
       "      <th>stl_per_min</th>\n",
       "      <th>tov_per_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>27.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>34.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>69.9</td>\n",
       "      <td>0.270073</td>\n",
       "      <td>0.069343</td>\n",
       "      <td>0.149635</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.047445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>26.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.267658</td>\n",
       "      <td>0.137546</td>\n",
       "      <td>0.089219</td>\n",
       "      <td>0.018587</td>\n",
       "      <td>0.040892</td>\n",
       "      <td>0.059480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>42.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>24.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.339869</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.143791</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.032680</td>\n",
       "      <td>0.065359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>11.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>68.9</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.163793</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.086207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>11.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>67.4</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.034783</td>\n",
       "      <td>0.026087</td>\n",
       "      <td>0.069565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>75</td>\n",
       "      <td>11.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>42.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>73.2</td>\n",
       "      <td>0.324561</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.061404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>81.1</td>\n",
       "      <td>0.605505</td>\n",
       "      <td>0.055046</td>\n",
       "      <td>0.183486</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.064220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48</td>\n",
       "      <td>10.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>41.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>87.5</td>\n",
       "      <td>0.553398</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.165049</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.067961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>71.4</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>38.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>67.8</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.129412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.082353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gp   min  fga    fg  3pa    3p  fta    ft  pts_per_min  ast_per_min  \\\n",
       "0  36  27.4  7.6  34.7  2.1  25.0  2.3  69.9     0.270073     0.069343   \n",
       "1  35  26.9  6.7  29.6  2.8  23.5  3.4  76.5     0.267658     0.137546   \n",
       "2  74  15.3  4.7  42.2  1.7  24.4  1.3  67.0     0.339869     0.065359   \n",
       "3  58  11.6  5.5  42.6  0.5  22.6  1.3  68.9     0.491379     0.068966   \n",
       "4  48  11.5  3.0  52.4  0.1   0.0  1.9  67.4     0.391304     0.026087   \n",
       "5  75  11.4  3.5  42.3  1.1  32.5  0.5  73.2     0.324561     0.157895   \n",
       "6  62  10.9  5.8  43.5  0.1  50.0  1.8  81.1     0.605505     0.055046   \n",
       "7  48  10.3  5.4  41.5  1.5  30.0  0.8  87.5     0.553398     0.019417   \n",
       "8  65   9.9  2.4  39.2  0.5  23.3  0.5  71.4     0.242424     0.232323   \n",
       "9  42   8.5  3.5  38.3  0.3  21.4  1.4  67.8     0.435294     0.035294   \n",
       "\n",
       "   reb_per_min  blk_per_min  stl_per_min  tov_per_min  \n",
       "0     0.149635     0.014599     0.014599     0.047445  \n",
       "1     0.089219     0.018587     0.040892     0.059480  \n",
       "2     0.143791     0.019608     0.032680     0.065359  \n",
       "3     0.163793     0.008621     0.051724     0.086207  \n",
       "4     0.217391     0.034783     0.026087     0.069565  \n",
       "5     0.070175     0.000000     0.035088     0.061404  \n",
       "6     0.183486     0.009174     0.018349     0.064220  \n",
       "7     0.165049     0.009709     0.019417     0.067961  \n",
       "8     0.080808     0.000000     0.030303     0.111111  \n",
       "9     0.129412     0.000000     0.023529     0.082353  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows of your predictor variables.\n",
    "### YOUR CODE HERE ###\n",
    "df_x.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Albdy39HZwQT"
   },
   "source": [
    "**Question:** What do you observe about the your predictor variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oD5l-FnazDYh"
   },
   "source": [
    "All of the predictors are continuous variables, but they likely won't all be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQ-wo4UOoBII"
   },
   "source": [
    "### Perform a split operation on your data\n",
    "\n",
    "Divide your data into a training set (75% of data) and test set (25% of data). This is an important step in the process, as it allows you to reserve a part of the data that the model has not observed. This tests how well the model generalizes—or performs—on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pO2AdPR7oBIJ"
   },
   "outputs": [],
   "source": [
    "# Perform the split operation on your data.\n",
    "# Assign the outputs as follows: X_train, X_test, y_train, y_test.\n",
    "### YOUR CODE HERE ###\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(df_x, df_y, stratify=df_y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgY9icEY2mKn"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about splitting your data between a training and test set](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/VxbUT/construct-a-naive-bayes-model-with-python).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUmzKZUU2mKp"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Call the function in the `model_selection` module of `sklearn` on the features and target variable, in order to perform the splitting.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORy1MNR62mKq"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call the `model_selection.train_test_split()` function, passing in both `features` and `target`, while configuring the appropriate `test_size`.\n",
    "\n",
    "Assign the output of this split as `X_train`, `X_test`, `y_train`, `y_test`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gjasizab0tSL"
   },
   "source": [
    "### Print the shape of each output \n",
    "\n",
    "Print the shape of each output from your train-test split. This will verify that the split operated as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xtxpSjCm4jCa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(938, 14)\n",
      "(402, 14)\n",
      "(938,)\n",
      "(402,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape (rows, columns) of the output from the train-test split.\n",
    "# Print the shape of X_train.\n",
    "### YOUR CODE HERE ###\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_test.\n",
    "### YOUR CODE HERE ###\n",
    "print(X_test.shape)\n",
    "\n",
    "# Print the shape of y_train.\n",
    "### YOUR CODE HERE ###\n",
    "print(y_train.shape)\n",
    "\n",
    "# Print the shape of y_test.\n",
    "### YOUR CODE HERE ###\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dx8DO1Rw2ZBZ"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Call the attribute that DataFrames in `pandas` have to get the number of rows and number of columns as a tuple.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9pDSxlG2di1"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Call the `shape` attribute.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZndsnPq1UyL"
   },
   "source": [
    "**Question:** How many rows are in each of the outputs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74-KZfWUzBeV"
   },
   "source": [
    "There are 938 rows in X_train and y_train, and 402 rows in X_test and y_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G5xBrJAZwlE"
   },
   "source": [
    "**Question:** What was the effect of the train-test split?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6MlJiZNzA9A"
   },
   "source": [
    "The train-test split divided the data into a training set (70% of the data) and test set (30% of the data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY0rAjlZAheh"
   },
   "source": [
    "## Step 3: Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YS06KhTSoBIM"
   },
   "source": [
    "**Question:** Which Naive Bayes algorithm should you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajt2BYgjzALD"
   },
   "source": [
    "I will try a GaussianNB first since all of my predictor variables are continuous (though some are unlikely to be normally distributed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOBvfCNeoBIM"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about different implementations of the Naive Bayes](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/supplement/1zfDy/naive-bayes-classifiers) to determine which is appropriate in this situation.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzT16WHjoBIM"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Note that you are performing binary classification.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IILInxLYoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "You can identify the appropriate algorithm to use because you are performing a binary classification and assuming that the features of your model follow a normal distribution.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5EFtZfXoBIN"
   },
   "source": [
    "### Fit your model to your training data and predict on your test data\n",
    "\n",
    "By creating your model, you will be drawing on your feature engineering work by training the classifier on the `X_train` DataFrame. You will use this to predict `target_5yrs` from `y_train`.\n",
    "\n",
    "Start by defining `nb` to be the relevant algorithm from `sklearn`.`naive_bayes`. Then fit your model to your training data. Use this fitted model to create predictions for your test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gUEgzQW_6oMV"
   },
   "outputs": [],
   "source": [
    "# Assign `nb` to be the appropriate implementation of Naive Bayes.\n",
    "### YOUR CODE HERE ###\n",
    "nb = naive_bayes.GaussianNB()\n",
    "\n",
    "# Fit the model on your training data.\n",
    "### YOUR CODE HERE ###\n",
    "clf = nb.fit(X_train, y_train)\n",
    "\n",
    "# Apply your model to predict on your test data. Call this \"y_pred\".\n",
    "### YOUR CODE HERE ###\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2vRT5XeoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about constructing a Naive Bayes](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/VxbUT/construct-a-naive-bayes-model-with-python).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo1E7RjtoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "The appropriate implementation in this case is `naive_bayes`.`GaussianNB()`. Fit this model to your training data and predict on your test data.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azSq51xXoBIN"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call `fit()`and pass your training feature set and target variable. Then call `predict()` on your test feature set.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgV_6xAQAvgg"
   },
   "source": [
    "## Step 4: Results and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPswDdr1oBIO"
   },
   "source": [
    "### Leverage metrics to evaluate your model's performance\n",
    "\n",
    "To evaluate the data yielded from your model, you can leverage a series of metrics and evaluation techniques from scikit-learn by examining the actual observed values in the test set relative to your model's prediction. Specifically, print the accuracy score, precision score, recall score, and f1 score associated with your test data and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "INf2Rd_MoBIP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.654228855721393\n",
      "Precision: 0.7864583333333334\n",
      "Recall: 0.606425702811245\n",
      "F1 score: 0.6848072562358276\n"
     ]
    }
   ],
   "source": [
    "# Print your accuracy score.\n",
    "### YOUR CODE HERE ###\n",
    "print('Accuracy:', metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Print your precision score.\n",
    "### YOUR CODE HERE ###\n",
    "print('Precision:', metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Print your recall score.\n",
    "### YOUR CODE HERE ###\n",
    "print('Recall:', metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "# Print your f1 score.\n",
    "### YOUR CODE HERE ###\n",
    "print('F1 score:', metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEgb0a2YoBIP"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "Refer to [the content about model evaluation](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/lecture/EITmV/key-evaluation-metrics-for-classification-models) for detail on these metrics.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oT143KsSoBIP"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "The `metrics` module in `sklearn` has a function for computing each of these metrics.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BECv4a2toBIP"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 3</strong></h4></summary>\n",
    "\n",
    "Call `accuracy_score()`, `precision_score()`, `recall_score()`, and `f1_score()`, passing `y_test`, and `y_pred` into each function.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDx7rrdNoBIP"
   },
   "source": [
    "**Question:** What is the accuracy score for your model, and what does this tell you about the success of the model's performance?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oD9Wu2eEy-CC"
   },
   "source": [
    "The accuracy of the model was 0.654. In this case, it is not very informative because I previously checked the class balance and found that it is split ~62/38."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3O1G_TIaaGw"
   },
   "source": [
    "**Question:** Can you evaluate the success of your model by using the accuracy score exclusively?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fd9zpsZFy9cP"
   },
   "source": [
    "No, accuracy score is not a great metric in cases with class imbalance, as it might overestimate model performance when the minority class is simply never predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evpAa_4noBIP"
   },
   "source": [
    "**Question:** What are the precision and recall scores for your model, and what do they mean? Is one of these scores more accurate than the other?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Di-uEPDTy8MW"
   },
   "source": [
    "The precision was 0.786 and recall was 0.606. Precision indicates that ratio of true positives to total predicted positives. Recall is the ratio of true positives to total observed positives. It doesn't make sense to say that one is \"more accurate\" than the other: precision and recall are calculated using similar formulas. However, I assume the question means is one value higher than the other for this specific model. The answer to this question is yes, the precision was higher than recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ghkTwSUoBIP"
   },
   "source": [
    "**Question:** What is the F1 score of your model, and what does this score mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEUUWvrmy7aE"
   },
   "source": [
    "The F1 score is 0.685. F1 score is a balance between precision and recall (harmonic mean). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNzDfI3RoBIQ"
   },
   "source": [
    "### Gain clarity with the confusion matrix\n",
    "\n",
    "Recall that a confusion matrix is a graphic that shows your model's true and false positives and negatives. It helps to create a visual representation of the components feeding into the metrics.\n",
    "\n",
    "Create a confusion matrix based on your predicted values for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ntoJ-YG7oBIQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x748f3c078cd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construct and display your confusion matrix.\n",
    "# Construct the confusion matrix for your predicted and test values.\n",
    "### YOUR CODE HERE ###\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create the display for your confusion matrix.\n",
    "### YOUR CODE HERE ###\n",
    "disp = metrics.ConfusionMatrixDisplay(cm, display_labels=['<5yrs', '>=5yrs'])\n",
    "\n",
    "# Plot the visual in-line.\n",
    "### YOUR CODE HERE ###\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2lqmzQ-oBIQ"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 1</strong></h4></summary>\n",
    "\n",
    "The `metrics` module has functions to create a confusion matrix.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi_x2zTDoBIQ"
   },
   "source": [
    "<details>\n",
    "<summary><h4><strong>Hint 2</strong></h4></summary>\n",
    "\n",
    "Call `confusion_matrix`, passing in `y_test` and `y_pred`. Then, utilize `ConfusionMatrixDisplay()` to display your confusion matrix.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLkF5znkNk7m"
   },
   "source": [
    "**Question:** What do you notice when observing your confusion matrix, and does this correlate to any of your other calculations?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA2eAI9Dy6OJ"
   },
   "source": [
    "The number of false positives is about half the number of false negatives, which is consistent with precision being higher than recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xur2FC5xAzp0"
   },
   "source": [
    "## Considerations\n",
    "\n",
    "**What are some key takeaways that you learned from this lab?**\n",
    "\n",
    "I learned how to fit a Naive Bayes model, which I have never tried before. Naive Bayes can perform reasonably well \"out-of-the-box\", even when some of the assumptions are violated.\n",
    "\n",
    "\n",
    "**How would you present your results to your team?**\n",
    "\n",
    "I would present the precision, recall, F1 score, and AUC (would also perform this as well), as well as the confusion matrix.\n",
    "\n",
    "\n",
    "**How would you summarize your findings to stakeholders?**\n",
    "\n",
    "The Naive Bayes classifer had an overall prediction score of 0.685 (on a scale from 0-1). This suggests that the model is able to make some valuable predictions, but can likely be improved further through exploring additional features or the features of players that were misclassified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations!** You've completed this lab. However, you may not notice a green check mark next to this item on Coursera's platform. Please continue your progress regardless of the check mark. Just click on the \"save\" icon at the top of this notebook to ensure your work has been logged"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
